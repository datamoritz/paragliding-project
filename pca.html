<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <!-- ======= Section Outline ======= -->
  <nav class="mb-4">
    <ul class="nav nav-pills justify-content-center flex-wrap small">
      <li class="nav-item"><a class="nav-link" href="#overview">Overview</a></li>
      <li class="nav-item"><a class="nav-link" href="#data">Data</a></li>
      <li class="nav-item"><a class="nav-link" href="#code">Code</a></li>
      <li class="nav-item"><a class="nav-link" href="#results">Results</a></li>
      <li class="nav-item"><a class="nav-link" href="#conclusions">Conclusions</a></li>
    </ul>
  </nav>
  
  <!-- ======= Smooth Scroll Behavior ======= -->
  <style>
    html {
      scroll-behavior: smooth;
    }
    .nav-pills .nav-link {
      color: #555;
      border-radius: 20px;
      margin: 3px;
    }
    .nav-pills .nav-link.active {
      background-color: #0d6efd;
    }
  </style>
  
  <title>PCA - Paragliding ML Project</title>
  <!-- Bootstrap CSS -->
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/css/bootstrap.min.css" rel="stylesheet">
  <style>
    p { text-align: justify; }
    h4 {
      font-size: 1.05rem;       /* smaller than Bootstrap default (~1.5rem) */
      font-weight: 600;         /* semi-bold */
      margin-top: 1.2rem;
      margin-bottom: 0.4rem;
      color: #333;
      text-transform: uppercase;
      letter-spacing: 0.5px;
    }
    figcaption { font-size: 0.82rem; }
  </style>
</head>
<body>

  <!-- Navbar -->
  <nav class="navbar navbar-expand-lg navbar-dark bg-dark">
    <div class="container-fluid">
      <a class="navbar-brand" href="index.html">Paragliding ML</a>
      <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNavDropdown" aria-controls="navbarNavDropdown" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>

      <div class="collapse navbar-collapse" id="navbarNavDropdown">
        <ul class="navbar-nav ms-auto">
          <li class="nav-item"><a class="nav-link" href="introduction.html">Introduction</a></li>
          <li class="nav-item"><a class="nav-link" href="dataprep.html">Data Prep / EDA</a></li>
          <li class="nav-item dropdown">
            <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">ML Models</a>
            <ul class="dropdown-menu" aria-labelledby="navbarDropdown">
              <li><a class="dropdown-item" href="clustering.html">Clustering</a></li>
              <li><a class="dropdown-item active" href="pca.html">PCA</a></li>
              <li><a class="dropdown-item" href="naivebayes.html">Naive Bayes</a></li>
              <li><a class="dropdown-item" href="decisiontrees.html">Decision Trees</a></li>
              <li><a class="dropdown-item" href="svm.html">SVMs</a></li>
              <li><a class="dropdown-item" href="regression.html">Regression</a></li>
              <li><a class="dropdown-item" href="nn.html">Neural Networks</a></li>
            </ul>
          </li>
          <li class="nav-item"><a class="nav-link" href="conclusions.html">Conclusions</a></li>
        </ul>
      </div>
    </div>
  </nav>

  <!-- Content -->
  <div class="container mt-5">
    <div class="col-lg-8 mx-auto">

      <h1 class="fw-bold mb-4">PCA (Principal Component Analysis)</h1>
      <hr>

      <h3 id="overview">Overview</h3>
      <p>
        For every thermal, i.e. row in the thermal dataset, there is a large amount of weather variables (wind, temperature, cloud base, etc.). This can slow machine learning algorithms down and is difficult to visualize. The goal of this section is to introduce a method to significantly reduce the dimensions of our thermals dataset. 
        Principal Component Analysis (PCA) is a powerful dimensionality reduction technique that reduces the number of features while retaining most of the information. This is achieved by finding correlations between variables and transforming them into new, uncorrelated variables (principal components).
      </p>

      <h4>Curse of Dimensionality</h4>
      <p>
        High-dimensional data presents several challenges known as the curse of dimensionality:
        <ul>
          <li>Sparsity: data points become spread out, making patterns harder to detect</li>
          <li>Computational cost: algorithms become exponentially slower</li>
          <li>Distance distortion: distances between points lose meaning</li>
          <li>Overfitting risk: models may learn noise instead of structure</li>
        </ul>
        PCA mitigates these issues by compressing data into fewer, more informative dimensions—making it denser, faster to process, and easier to visualize.
      </p>

      <h4>Eigenvectors and Eigenvalues</h4>
      <p>
        PCA identifies combinations of features that explain the most variance. Each principal component is a linear combination of the original variables. 
        <ul>
          <li><strong>Eigenvectors</strong> represent directions of maximum variance (axes of new space).</li>
          <li><strong>Eigenvalues</strong> indicate the magnitude of variance along each direction.</li>
        </ul>
        Larger eigenvalues capture more structure in the dataset. PCA selects the top few eigenvectors (principal components) that retain most of the information.
      </p>

      <h4>Dimensionality Reduction</h4>
      <p>
        Dimensionality reduction decreases the number of input features while preserving as much relevant information as possible. 
        <ul>
          <li><strong>Simplifies analysis:</strong> fewer variables = easier interpretation</li>
          <li><strong>Improves visualization:</strong> enables 2D or 3D plotting</li>
          <li><strong>Reduces noise:</strong> filters out uninformative variation</li>
          <li><strong>Prevents overfitting:</strong> fewer redundant features improve generalization</li>
        </ul>
        However, principal components no longer correspond directly to original variables—reducing interpretability.
      </p>

      <!-- Two images side by side -->
      <div class="d-flex justify-content-center align-items-start mt-4 gap-3">
        <figure class="text-center" style="width: 48%;">
          <img src="PCA_1.gif"
               alt="PCA projection 2D" 
               class="img-fluid rounded shadow-sm">
          <figcaption class="mt-2 text-muted small">
            Projection of 2D data (x, y) onto first principal component (black line); red lines show orthogonal projections capturing maximum variance.
          </figcaption>
        </figure>
      
        <figure class="text-center" style="width: 48%;">
          <img src="PCA_2.png"
               alt="PCA components in 2D" 
               class="img-fluid rounded shadow-sm">
          <figcaption class="mt-2 text-muted small">
            Principal components in 2D: V1 captures maximum variance along the data spread; V2 is orthogonal and captures remaining variance.
          </figcaption>
        </figure>
      </div>

      <h3 id="data">Data</h3>
      <p>
        PCA requires numerical, continuous data where each column represents a variable and each row represents an observation. 
        Data must be standardized, since PCA is sensitive to differences in scale. 
        Categorical or text variables must be numerically encoded (e.g. one-hot). 
        PCA assumes roughly linear relationships between variables for meaningful variance capture.
      </p>
      <h3 id="code">Code</h3>
      <p>Link to GitHub repository and code examples.</p>

      <h3 id="results">Results</h3>
      <p>Summarize PCA results and visualizations here.</p>
      
      <h3 id="conclusions">Conclusions</h3>
      <p>Wrap up key insights and interpretations from PCA.</p>    

    </div>
  </div>

  <!-- Bootstrap JS -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/js/bootstrap.bundle.min.js"></script>
</body>
</html>
